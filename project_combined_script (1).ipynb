{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgSR6MLOrhxm",
        "outputId": "a1ac7ab6-7f47-4724-a542-49fe14193f9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17413, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 17413 (delta 64), reused 22 (delta 22), pack-reused 17327 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17413/17413), 16.31 MiB | 17.08 MiB/s, done.\n",
            "Resolving deltas: 100% (11932/11932), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.15.2)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.3.122-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.122-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238 ultralytics-8.3.122 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics supervision pytesseract\n",
        "!apt-get update && apt-get install -y libgl1-mesa-glx\n",
        "!apt-get install tesseract-ocr -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvO-U87Ls3ku",
        "outputId": "ee5d33fc-a2b3-4151-c908-73587fa18c25"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.122)\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from supervision) (1.3.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract, supervision\n",
            "Successfully installed pytesseract-0.3.13 supervision-0.25.1\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,607 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,869 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,244 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,844 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,544 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,701 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,155 kB]\n",
            "Fetched 22.4 MB in 5s (4,186 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddleocr paddlepaddle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnsF9XbM9hgx",
        "outputId": "d459daae-3113-43fb-8f81-6759044357d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paddleocr\n",
            "  Downloading paddleocr-2.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting paddlepaddle\n",
            "  Downloading paddlepaddle-3.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.25.2)\n",
            "Collecting pyclipper (from paddleocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting lmdb (from paddleocr)\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.0.2)\n",
            "Collecting rapidfuzz (from paddleocr)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from paddleocr) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddleocr) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from paddleocr) (6.0.2)\n",
            "Collecting python-docx (from paddleocr)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.13.4)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.57.0)\n",
            "Collecting fire>=0.3.0 (from paddleocr)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.32.3)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.0.5)\n",
            "Requirement already satisfied: albucore in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.0.23)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (0.28.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (5.29.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Collecting astor (from paddlepaddle)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting opt_einsum==3.3.0 (from paddlepaddle)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (3.4.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (4.13.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.3.0->paddleocr) (3.0.1)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore->paddleocr) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore->paddleocr) (6.2.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albucore->paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations->paddleocr) (1.15.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->paddleocr) (2.11.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->paddleocr) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->paddlepaddle) (0.16.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->paddleocr) (5.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (2.4.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (0.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->paddleocr) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->paddleocr) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle) (1.3.1)\n",
            "Downloading paddleocr-2.10.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddlepaddle-3.0.0-cp311-cp311-manylinux1_x86_64.whl (192.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.8/192.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=7e75501ed4a273ee790d7e14a1a1d47ccc184369e1effc727d53bbb4de1850e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: pyclipper, lmdb, rapidfuzz, python-docx, opt_einsum, fire, astor, paddlepaddle, paddleocr\n",
            "  Attempting uninstall: opt_einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "Successfully installed astor-0.8.1 fire-0.7.0 lmdb-1.6.2 opt_einsum-3.3.0 paddleocr-2.10.0 paddlepaddle-3.0.0 pyclipper-1.3.0.post6 python-docx-1.1.2 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5GpGKsFVo2ZG",
        "outputId": "20766206-0e6f-49fb-9dae-fca662786809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Enhanced Traffic Compliance System - Deep Learning Project\n",
            "==================================================\n",
            "This system can detect:\n",
            "1. Standard traffic violations (speeding, lane changes)\n",
            "2. Multiple riders on motorcycles (>2 people)\n",
            "3. Riders without helmets\n",
            "4. License plate recognition\n",
            "==================================================\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.25M/6.25M [00:00<00:00, 93.0MB/s]\n",
            "Using general purpose model for helmet detection. Fine-tuning recommended for better results.\n",
            "Processing video for violations...\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 bus, 52.4ms\n",
            "Speed: 6.0ms preprocess, 52.4ms inference, 409.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 7.5ms\n",
            "Speed: 1.3ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 1 car, 4 motorcycles, 1 bus, 2 umbrellas, 7.9ms\n",
            "Speed: 1.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 bus, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 13.9ms\n",
            "Speed: 1.9ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 bicycles, 1 car, 3 motorcycles, 1 bus, 2 umbrellas, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 1 bus, 14.4ms\n",
            "Speed: 1.8ms preprocess, 14.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 19.0ms\n",
            "Speed: 1.8ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 car, 5 motorcycles, 1 bus, 1 umbrella, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 1 bus, 19.8ms\n",
            "Speed: 1.8ms preprocess, 19.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 13.7ms\n",
            "Speed: 1.7ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 bicycles, 1 car, 5 motorcycles, 1 bus, 1 umbrella, 8.7ms\n",
            "Speed: 2.0ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 12.6ms\n",
            "Speed: 1.7ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 car, 5 motorcycles, 9.3ms\n",
            "Speed: 1.2ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 7.9ms\n",
            "Speed: 1.6ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 1 car, 3 motorcycles, 1 truck, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 bicycles, 1 car, 3 motorcycles, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 11.2ms\n",
            "Speed: 1.7ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 car, 4 motorcycles, 1 umbrella, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 11.2ms\n",
            "Speed: 1.7ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 1 car, 4 motorcycles, 1 umbrella, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 9.7ms\n",
            "Speed: 1.6ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 4 motorcycles, 1 umbrella, 8.7ms\n",
            "Speed: 1.8ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 4 motorcycles, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 4 motorcycles, 1 truck, 1 traffic light, 1 umbrella, 9.1ms\n",
            "Speed: 1.2ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 9.2ms\n",
            "Speed: 4.2ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 9.8ms\n",
            "Speed: 1.6ms preprocess, 9.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 4 motorcycles, 1 truck, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 11.8ms\n",
            "Speed: 1.7ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 12.2ms\n",
            "Speed: 1.8ms preprocess, 12.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 4 motorcycles, 1 truck, 1 umbrella, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 4 motorcycles, 1 truck, 1 umbrella, 12.8ms\n",
            "Speed: 1.7ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 10.9ms\n",
            "Speed: 1.8ms preprocess, 10.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 15.1ms\n",
            "Speed: 1.6ms preprocess, 15.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 bicycles, 1 car, 3 motorcycles, 1 truck, 2 umbrellas, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 1 truck, 13.3ms\n",
            "Speed: 1.8ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 2 umbrellas, 12.3ms\n",
            "Speed: 1.6ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 12.3ms\n",
            "Speed: 1.8ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 3 motorcycles, 1 truck, 1 umbrella, 11.7ms\n",
            "Speed: 1.6ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 1 truck, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 12.8ms\n",
            "Speed: 1.5ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 5 motorcycles, 1 truck, 1 umbrella, 13.0ms\n",
            "Speed: 1.7ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x576 (no detections), 49.1ms\n",
            "Speed: 10.9ms preprocess, 49.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 7.4ms\n",
            "Speed: 2.0ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 3 motorcycles, 1 truck, 1 umbrella, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 2.0ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 7.3ms\n",
            "Speed: 1.2ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 5 motorcycles, 1 truck, 1 umbrella, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 3 motorcycles, 1 truck, 7.3ms\n",
            "Speed: 1.5ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 3 motorcycles, 1 truck, 1 umbrella, 7.1ms\n",
            "Speed: 1.3ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 4 motorcycles, 1 truck, 7.2ms\n",
            "Speed: 1.9ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 4 motorcycles, 1 truck, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 1 car, 4 motorcycles, 1 truck, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 7.2ms\n",
            "Speed: 1.5ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 1 car, 4 motorcycles, 1 truck, 2 umbrellas, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 4 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 4 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 1 truck, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 8.0ms\n",
            "Speed: 1.2ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 4 motorcycles, 1 truck, 1 umbrella, 7.2ms\n",
            "Speed: 1.2ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 6 motorcycles, 1 truck, 11.1ms\n",
            "Speed: 1.5ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 13.1ms\n",
            "Speed: 1.7ms preprocess, 13.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 6 motorcycles, 1 truck, 1 umbrella, 8.6ms\n",
            "Speed: 1.5ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.4ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 7.3ms\n",
            "Speed: 1.3ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 5 motorcycles, 1 truck, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 5 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 5 motorcycles, 1 truck, 2 umbrellas, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 1 truck, 7.5ms\n",
            "Speed: 1.7ms preprocess, 7.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 motorcycles, 1 truck, 2 umbrellas, 7.4ms\n",
            "Speed: 1.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x352 (no detections), 45.3ms\n",
            "Speed: 1.5ms preprocess, 45.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 384x640 5 motorcycles, 1 truck, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 7.1ms\n",
            "Speed: 1.4ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 5 motorcycles, 1 truck, 2 umbrellas, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x416 (no detections), 41.1ms\n",
            "Speed: 2.0ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 7.1ms\n",
            "Speed: 1.5ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 7.4ms\n",
            "Speed: 1.2ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 motorcycles, 1 truck, 7.4ms\n",
            "Speed: 1.2ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x352 (no detections), 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 buss, 1 truck, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 motorcycles, 2 buss, 1 truck, 2 umbrellas, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x352 (no detections), 8.7ms\n",
            "Speed: 1.3ms preprocess, 8.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 352)\n",
            "Processed 100 frames out of 572 (17.5%)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 motorcycles, 1 truck, 1 umbrella, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x384 (no detections), 64.4ms\n",
            "Speed: 2.2ms preprocess, 64.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 21.6ms\n",
            "Speed: 3.6ms preprocess, 21.6ms inference, 8.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 3 motorcycles, 1 truck, 1 umbrella, 25.6ms\n",
            "Speed: 3.9ms preprocess, 25.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x384 (no detections), 25.2ms\n",
            "Speed: 15.8ms preprocess, 25.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 30.7ms\n",
            "Speed: 1.9ms preprocess, 30.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 40.5ms\n",
            "Speed: 26.8ms preprocess, 40.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 motorcycles, 1 truck, 1 umbrella, 13.7ms\n",
            "Speed: 8.3ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 1 truck, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 8.5ms\n",
            "Speed: 2.6ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 motorcycles, 1 truck, 1 umbrella, 8.3ms\n",
            "Speed: 1.7ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 9.0ms\n",
            "Speed: 1.8ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 1 car, 3 motorcycles, 1 truck, 2 umbrellas, 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 1 truck, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 bicycles, 4 motorcycles, 1 truck, 2 umbrellas, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 motorcycles, 1 truck, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 13.1ms\n",
            "Speed: 1.7ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 bicycles, 7 motorcycles, 1 truck, 2 umbrellas, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 14.9ms\n",
            "Speed: 3.0ms preprocess, 14.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 14.6ms\n",
            "Speed: 2.0ms preprocess, 14.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 4 motorcycles, 2 umbrellas, 13.6ms\n",
            "Speed: 1.7ms preprocess, 13.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 bicycles, 3 motorcycles, 1 truck, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 1 truck, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 1 car, 3 motorcycles, 1 truck, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 car, 2 motorcycles, 1 truck, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 car, 3 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 7.3ms\n",
            "Speed: 1.5ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 truck, 7.2ms\n",
            "Speed: 1.3ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.2ms\n",
            "Speed: 1.5ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6.4ms\n",
            "Speed: 1.1ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 motorcycles, 1 truck, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 3 motorcycles, 1 truck, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 9.1ms\n",
            "Speed: 1.7ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 6.5ms\n",
            "Speed: 1.4ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 3 motorcycles, 1 truck, 9.6ms\n",
            "Speed: 1.5ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 motorcycles, 1 truck, 12.0ms\n",
            "Speed: 1.8ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 5 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 7.0ms\n",
            "Speed: 1.1ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 3 motorcycles, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 6.9ms\n",
            "Speed: 1.8ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 bicycle, 1 car, 3 motorcycles, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 7.2ms\n",
            "Speed: 1.7ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 car, 3 motorcycles, 1 umbrella, 7.0ms\n",
            "Speed: 2.4ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 4 motorcycles, 7.1ms\n",
            "Speed: 1.6ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 car, 4 motorcycles, 1 umbrella, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 bus, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.4ms\n",
            "Speed: 1.1ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 3 motorcycles, 1 bus, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 7.1ms\n",
            "Speed: 1.7ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 4 motorcycles, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.2ms\n",
            "Speed: 1.7ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 motorcycles, 1 truck, 6.9ms\n",
            "Speed: 1.4ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 6.8ms\n",
            "Speed: 2.3ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 motorcycles, 2 umbrellas, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 7.2ms\n",
            "Speed: 1.5ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 motorcycles, 1 umbrella, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 2 motorcycles, 2 umbrellas, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 motorcycles, 2 umbrellas, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 motorcycles, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 11.3ms\n",
            "Speed: 1.6ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 motorcycles, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 bicycle, 3 motorcycles, 1 truck, 2 umbrellas, 6.4ms\n",
            "Speed: 1.3ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 motorcycles, 2 umbrellas, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 9.6ms\n",
            "Speed: 1.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 motorcycles, 1 truck, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 2 motorcycles, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 2 motorcycles, 1 umbrella, 8.9ms\n",
            "Speed: 1.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.3ms\n",
            "Speed: 1.6ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.4ms\n",
            "Speed: 1.4ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 motorcycles, 1 truck, 1 umbrella, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 1 truck, 2 umbrellas, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 3 motorcycles, 1 truck, 1 umbrella, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.7ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 bicycles, 2 motorcycles, 1 truck, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.3ms\n",
            "Speed: 1.2ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 2 motorcycles, 1 truck, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 2 motorcycles, 2 trucks, 1 umbrella, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 6.4ms\n",
            "Speed: 1.4ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 1 motorcycle, 2 trucks, 1 umbrella, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 7.3ms\n",
            "Speed: 1.3ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 2 trucks, 1 umbrella, 7.5ms\n",
            "Speed: 1.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 1 truck, 2 umbrellas, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 7.2ms\n",
            "Speed: 1.7ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 8.8ms\n",
            "Speed: 1.2ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 motorcycles, 2 trucks, 2 umbrellas, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 174.5ms\n",
            "Speed: 1.8ms preprocess, 174.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 motorcycles, 1 truck, 2 umbrellas, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.1ms\n",
            "Speed: 1.6ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 motorcycles, 2 trucks, 1 umbrella, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 6.9ms\n",
            "Speed: 1.6ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 trucks, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 250 frames out of 572 (43.7%)\n",
            "\n",
            "0: 384x640 2 trucks, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 trucks, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 trucks, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 trucks, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 6.6ms\n",
            "Speed: 1.5ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 trucks, 1 umbrella, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 7.3ms\n",
            "Speed: 1.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 1 truck, 1 umbrella, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 6.8ms\n",
            "Speed: 1.6ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 trucks, 2 umbrellas, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 8.6ms\n",
            "Speed: 1.3ms preprocess, 8.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 12.8ms\n",
            "Speed: 1.8ms preprocess, 12.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 2 trucks, 1 umbrella, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 3 trucks, 7.0ms\n",
            "Speed: 1.5ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.2ms\n",
            "Speed: 1.2ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 motorcycle, 3 trucks, 2 umbrellas, 7.2ms\n",
            "Speed: 1.3ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 7.4ms\n",
            "Speed: 1.5ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 7.1ms\n",
            "Speed: 2.3ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 motorcycle, 1 truck, 2 umbrellas, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 6.9ms\n",
            "Speed: 2.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 2 trucks, 2 umbrellas, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 1 truck, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 9.0ms\n",
            "Speed: 1.4ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 2 umbrellas, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 1 truck, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 2 motorcycles, 1 truck, 2 umbrellas, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 motorcycle, 1 truck, 2 umbrellas, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 1 truck, 2 umbrellas, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 7.0ms\n",
            "Speed: 1.4ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 truck, 2 umbrellas, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.7ms\n",
            "Speed: 1.3ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 1 truck, 2 umbrellas, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 8.6ms\n",
            "Speed: 1.1ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 truck, 2 umbrellas, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 1 truck, 2 umbrellas, 8.6ms\n",
            "Speed: 1.1ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.4ms\n",
            "Speed: 1.5ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 truck, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 truck, 1 umbrella, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 motorcycle, 1 truck, 1 umbrella, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 7.2ms\n",
            "Speed: 1.8ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 trucks, 1 umbrella, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 1 truck, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 1 truck, 1 umbrella, 7.0ms\n",
            "Speed: 1.3ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 6.9ms\n",
            "Speed: 1.4ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 motorcycle, 2 trucks, 1 umbrella, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 2 trucks, 7.7ms\n",
            "Speed: 1.2ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 2 trucks, 1 umbrella, 8.8ms\n",
            "Speed: 1.2ms preprocess, 8.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 3 motorcycles, 2 trucks, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 motorcycles, 2 trucks, 1 umbrella, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.4ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.2ms\n",
            "Speed: 1.2ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 3 motorcycles, 1 truck, 1 umbrella, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 11.1ms\n",
            "Speed: 1.8ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 11.0ms\n",
            "Speed: 1.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x448 (no detections), 42.0ms\n",
            "Speed: 2.0ms preprocess, 42.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 motorcycles, 1 truck, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x416 (no detections), 9.4ms\n",
            "Speed: 1.6ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.4ms\n",
            "Speed: 1.6ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x448 (no detections), 9.6ms\n",
            "Speed: 1.7ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.3ms\n",
            "Speed: 1.7ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 3 motorcycles, 2 trucks, 7.2ms\n",
            "Speed: 1.2ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x416 (no detections), 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 3 motorcycles, 2 trucks, 7.8ms\n",
            "Speed: 1.2ms preprocess, 7.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.9ms\n",
            "Speed: 1.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 7.1ms\n",
            "Speed: 1.1ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 1 truck, 7.1ms\n",
            "Speed: 1.1ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 2 trucks, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.4ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 2 trucks, 1 umbrella, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 8.3ms\n",
            "Speed: 1.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 motorcycles, 1 truck, 1 umbrella, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 8.2ms\n",
            "Speed: 1.6ms preprocess, 8.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 2 trucks, 1 umbrella, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.5ms preprocess, 7.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 motorcycles, 1 truck, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 9.0ms\n",
            "Speed: 1.5ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 8.3ms\n",
            "Speed: 1.1ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 3 motorcycles, 1 truck, 12.7ms\n",
            "Speed: 1.7ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 2 trucks, 6.9ms\n",
            "Speed: 1.3ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 4 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 2 trucks, 7.3ms\n",
            "Speed: 1.9ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.3ms\n",
            "Speed: 1.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 bicycles, 4 motorcycles, 2 trucks, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 1 truck, 7.4ms\n",
            "Speed: 1.4ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 4 motorcycles, 1 truck, 7.3ms\n",
            "Speed: 1.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 1 truck, 7.2ms\n",
            "Speed: 1.6ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 4 motorcycles, 1 truck, 7.3ms\n",
            "Speed: 1.3ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 motorcycles, 2 trucks, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 7.5ms\n",
            "Speed: 1.3ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 4 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.3ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 7.3ms\n",
            "Speed: 1.2ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 3 motorcycles, 2 trucks, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 8.0ms\n",
            "Speed: 1.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 bicycle, 3 motorcycles, 2 trucks, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 7.1ms\n",
            "Speed: 1.4ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 bicycles, 3 motorcycles, 2 trucks, 9.7ms\n",
            "Speed: 1.4ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 9.3ms\n",
            "Speed: 1.5ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 2 motorcycles, 2 trucks, 1 suitcase, 11.9ms\n",
            "Speed: 1.8ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 1 truck, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 13.0ms\n",
            "Speed: 1.8ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 14.1ms\n",
            "Speed: 1.8ms preprocess, 14.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 bicycles, 2 motorcycles, 2 trucks, 14.0ms\n",
            "Speed: 1.9ms preprocess, 14.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 400 frames out of 572 (69.9%)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 2 motorcycles, 2 trucks, 9.4ms\n",
            "Speed: 1.7ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 bicycles, 2 motorcycles, 2 trucks, 14.6ms\n",
            "Speed: 1.7ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 12.3ms\n",
            "Speed: 1.7ms preprocess, 12.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 bicycle, 2 motorcycles, 2 trucks, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 9.0ms\n",
            "Speed: 1.6ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 2 trucks, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 11.0ms\n",
            "Speed: 1.7ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 2 motorcycles, 2 trucks, 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 11.4ms\n",
            "Speed: 1.6ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 2 trucks, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 2 trucks, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 3 motorcycles, 2 trucks, 9.2ms\n",
            "Speed: 1.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 2 trucks, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 12.9ms\n",
            "Speed: 1.7ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 3 motorcycles, 2 trucks, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 2 trucks, 12.5ms\n",
            "Speed: 1.7ms preprocess, 12.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 motorcycles, 2 trucks, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 2 trucks, 9.1ms\n",
            "Speed: 4.7ms preprocess, 9.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 motorcycles, 2 trucks, 9.7ms\n",
            "Speed: 1.7ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 9.2ms\n",
            "Speed: 1.8ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 8.4ms\n",
            "Speed: 1.8ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 2 trucks, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 14.2ms\n",
            "Speed: 1.6ms preprocess, 14.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 bicycles, 2 motorcycles, 2 trucks, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 9.0ms\n",
            "Speed: 1.9ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 1 truck, 8.5ms\n",
            "Speed: 1.8ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 2 trucks, 9.3ms\n",
            "Speed: 1.7ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 2 trucks, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 3 motorcycles, 1 truck, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 1 truck, 8.9ms\n",
            "Speed: 1.7ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 3 motorcycles, 1 truck, 8.7ms\n",
            "Speed: 1.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 1 bicycle, 2 motorcycles, 1 truck, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 11.7ms\n",
            "Speed: 1.9ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 12.7ms\n",
            "Speed: 1.8ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 2 motorcycles, 1 truck, 1 boat, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 20.3ms\n",
            "Speed: 1.9ms preprocess, 20.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 12.9ms\n",
            "Speed: 4.6ms preprocess, 12.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 1 truck, 1 boat, 13.7ms\n",
            "Speed: 1.5ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 motorcycles, 13.8ms\n",
            "Speed: 1.7ms preprocess, 13.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 10.5ms\n",
            "Speed: 1.6ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 3 motorcycles, 1 chair, 16.4ms\n",
            "Speed: 5.6ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 8.4ms\n",
            "Speed: 1.6ms preprocess, 8.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 12.4ms\n",
            "Speed: 1.5ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 2 motorcycles, 11.0ms\n",
            "Speed: 1.6ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 11.7ms\n",
            "Speed: 1.6ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 11.3ms\n",
            "Speed: 1.6ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 11.9ms\n",
            "Speed: 1.7ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 11.5ms\n",
            "Speed: 1.7ms preprocess, 11.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 1 truck, 1 backpack, 11.4ms\n",
            "Speed: 1.6ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 1 truck, 12.3ms\n",
            "Speed: 1.5ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 11.7ms\n",
            "Speed: 1.6ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 1 bicycle, 2 motorcycles, 1 truck, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 12.7ms\n",
            "Speed: 1.5ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 12.2ms\n",
            "Speed: 1.6ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 14.0ms\n",
            "Speed: 1.7ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 10.3ms\n",
            "Speed: 1.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 2 motorcycles, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 7.0ms\n",
            "Speed: 1.6ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 bicycle, 2 motorcycles, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 17.4ms\n",
            "Speed: 2.0ms preprocess, 17.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 motorcycles, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 7.1ms\n",
            "Speed: 1.6ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 8.1ms\n",
            "Speed: 1.2ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 motorcycles, 1 umbrella, 8.8ms\n",
            "Speed: 1.3ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 1 bus, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.8ms\n",
            "Speed: 1.1ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 2 motorcycles, 1 bus, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 1 bus, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.9ms\n",
            "Speed: 1.1ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 motorcycle, 1 bus, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 1 truck, 6.7ms\n",
            "Speed: 1.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 motorcycle, 1 truck, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 6.3ms\n",
            "Speed: 1.2ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 6.0ms\n",
            "Speed: 1.1ms preprocess, 6.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 3 motorcycles, 7.1ms\n",
            "Speed: 1.1ms preprocess, 7.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.6ms\n",
            "Speed: 1.1ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 3 motorcycles, 7.0ms\n",
            "Speed: 1.1ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 3 motorcycles, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 cars, 3 motorcycles, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.2ms\n",
            "Speed: 1.2ms preprocess, 6.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 bicycle, 1 car, 2 motorcycles, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6.4ms\n",
            "Speed: 1.1ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 bicycle, 3 cars, 2 motorcycles, 6.2ms\n",
            "Speed: 1.1ms preprocess, 6.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 motorcycle, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 bicycles, 3 cars, 1 motorcycle, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 7.2ms\n",
            "Speed: 1.3ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 bicycles, 1 car, 2 motorcycles, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6.4ms\n",
            "Speed: 1.1ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 bicycles, 1 car, 1 motorcycle, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 7.0ms\n",
            "Speed: 1.7ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.5ms\n",
            "Speed: 1.1ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 bicycles, 1 car, 1 motorcycle, 1 umbrella, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 7.4ms\n",
            "Speed: 1.5ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.4ms\n",
            "Speed: 1.2ms preprocess, 6.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 bicycles, 2 cars, 1 motorcycle, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 6.7ms\n",
            "Speed: 1.4ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 bicycle, 1 car, 1 motorcycle, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 8.8ms\n",
            "Speed: 1.5ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 car, 1 motorcycle, 1 airplane, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 motorcycles, 6.8ms\n",
            "Speed: 1.5ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 bicycles, 3 cars, 2 motorcycles, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 motorcycle, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 bicycles, 2 cars, 1 motorcycle, 1 umbrella, 6.5ms\n",
            "Speed: 1.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 motorcycles, 6.6ms\n",
            "Speed: 1.7ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 cars, 2 motorcycles, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 7.0ms\n",
            "Speed: 1.6ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 1 car, 2 motorcycles, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 motorcycles, 7.3ms\n",
            "Speed: 1.5ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 2 motorcycles, 9.0ms\n",
            "Speed: 1.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 7.1ms\n",
            "Speed: 1.3ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 7.1ms\n",
            "Speed: 1.2ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 motorcycle, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed 550 frames out of 572 (96.2%)\n",
            "\n",
            "0: 384x640 1 car, 3 motorcycles, 7.1ms\n",
            "Speed: 1.8ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 7.0ms\n",
            "Speed: 1.2ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 3 motorcycles, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 7.0ms\n",
            "Speed: 1.4ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 motorcycle, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 6.7ms\n",
            "Speed: 1.1ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 motorcycle, 8.5ms\n",
            "Speed: 1.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 6.6ms\n",
            "Speed: 1.3ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.9ms\n",
            "Speed: 1.5ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 motorcycles, 7.1ms\n",
            "Speed: 1.3ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 6.7ms\n",
            "Speed: 1.8ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 6.9ms\n",
            "Speed: 1.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 umbrella, 6.6ms\n",
            "Speed: 1.2ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 motorcycle, 6.8ms\n",
            "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 7.6ms\n",
            "Speed: 1.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 bicycle, 1 motorcycle, 2 umbrellas, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 motorcycles, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6.8ms\n",
            "Speed: 1.2ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 bicycle, 2 motorcycles, 2 umbrellas, 6.7ms\n",
            "Speed: 1.2ms preprocess, 6.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing complete! Output video saved to /content/drive/MyDrive/DL Project/traffic_compliance_system/processed_video.mp4\n",
            "Detected 11 violations\n",
            "Creating violations dashboard...\n",
            "FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "<IPython.core.display.Image object>\n",
            "Violation dashboard saved to /content/drive/MyDrive/DL Project/traffic_compliance_system/violations_dashboard.png\n",
            "Detailed report saved to /content/drive/MyDrive/DL Project/traffic_compliance_system/violations_report.html\n",
            "\n",
            "Project Results Summary:\n",
            "- Processed video saved to: /content/drive/MyDrive/DL Project/traffic_compliance_system/processed_video.mp4\n",
            "- Detected 11 violations\n",
            "- Violation records saved to: /content/drive/MyDrive/DL Project/traffic_compliance_system/violations_report.csv\n",
            "- Violation snapshots saved to: /content/drive/MyDrive/DL Project/traffic_compliance_system/detected_violations/\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/DL Project/model/best_3rider.pt'], source=/content/drive/MyDrive/DL Project/traffic_compliance_system/processed_video.mp4, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.3, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/traffic_compliance_outputs, name=filtered_output, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-416-gfe1d4d99 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n",
            "video 1/1 (1/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 31.9ms\n",
            "video 1/1 (2/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (3/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (4/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (5/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (6/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 10.6ms\n",
            "video 1/1 (7/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 12.5ms\n",
            "video 1/1 (8/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (9/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (10/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (11/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (12/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 9.3ms\n",
            "video 1/1 (13/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (14/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (15/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (16/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (17/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (18/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (19/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (20/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.5ms\n",
            "video 1/1 (21/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.1ms\n",
            "video 1/1 (22/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (23/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (24/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (25/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (26/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (27/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (28/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.5ms\n",
            "video 1/1 (29/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (30/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (31/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.7ms\n",
            "video 1/1 (32/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.3ms\n",
            "video 1/1 (33/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.5ms\n",
            "video 1/1 (34/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.0ms\n",
            "video 1/1 (35/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 MORE_THAN_TWO_PERSONS, 1 WITH_HELMET, 6.3ms\n",
            "video 1/1 (36/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.6ms\n",
            "video 1/1 (37/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.3ms\n",
            "video 1/1 (38/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (39/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 5.8ms\n",
            "video 1/1 (40/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (41/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.0ms\n",
            "video 1/1 (42/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.2ms\n",
            "video 1/1 (43/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 3 WITH_HELMETs, 6.1ms\n",
            "video 1/1 (44/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 3 WITH_HELMETs, 6.1ms\n",
            "video 1/1 (45/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 3 WITH_HELMETs, 6.1ms\n",
            "video 1/1 (46/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 3 WITH_HELMETs, 6.3ms\n",
            "video 1/1 (47/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.0ms\n",
            "video 1/1 (48/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (49/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.4ms\n",
            "video 1/1 (50/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.2ms\n",
            "video 1/1 (51/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 7.9ms\n",
            "video 1/1 (52/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (53/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.2ms\n",
            "video 1/1 (54/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.0ms\n",
            "video 1/1 (55/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.2ms\n",
            "video 1/1 (56/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.0ms\n",
            "video 1/1 (57/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 8.3ms\n",
            "video 1/1 (58/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.0ms\n",
            "video 1/1 (59/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.1ms\n",
            "video 1/1 (60/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITHOUT_HELMET, 2 WITH_HELMETs, 6.4ms\n",
            "video 1/1 (61/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITHOUT_HELMET, 1 WITH_HELMET, 6.0ms\n",
            "video 1/1 (62/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (63/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (64/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (65/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 5.9ms\n",
            "video 1/1 (66/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (67/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 8.4ms\n",
            "video 1/1 (68/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 11.4ms\n",
            "video 1/1 (69/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.8ms\n",
            "video 1/1 (70/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 7.1ms\n",
            "video 1/1 (71/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.6ms\n",
            "video 1/1 (72/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.4ms\n",
            "video 1/1 (73/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.4ms\n",
            "video 1/1 (74/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.4ms\n",
            "video 1/1 (75/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 8.2ms\n",
            "video 1/1 (76/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 8.0ms\n",
            "video 1/1 (77/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.3ms\n",
            "video 1/1 (78/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (79/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.7ms\n",
            "video 1/1 (80/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (81/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.6ms\n",
            "video 1/1 (82/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.3ms\n",
            "video 1/1 (83/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.5ms\n",
            "video 1/1 (84/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.9ms\n",
            "video 1/1 (85/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 7.0ms\n",
            "video 1/1 (86/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.4ms\n",
            "video 1/1 (87/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.9ms\n",
            "video 1/1 (88/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.7ms\n",
            "video 1/1 (89/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (90/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.3ms\n",
            "video 1/1 (91/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.6ms\n",
            "video 1/1 (92/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.4ms\n",
            "video 1/1 (93/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 USING_MOBILE, 8.3ms\n",
            "video 1/1 (94/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.6ms\n",
            "video 1/1 (95/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.4ms\n",
            "video 1/1 (96/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (97/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (98/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.7ms\n",
            "video 1/1 (99/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.3ms\n",
            "video 1/1 (100/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.3ms\n",
            "video 1/1 (101/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.0ms\n",
            "video 1/1 (102/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 2 WITH_HELMETs, 6.0ms\n",
            "video 1/1 (103/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (104/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (105/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.6ms\n",
            "video 1/1 (106/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (107/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (108/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (109/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (110/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.4ms\n",
            "video 1/1 (111/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.1ms\n",
            "video 1/1 (112/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 5.9ms\n",
            "video 1/1 (113/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 MORE_THAN_TWO_PERSONS, 1 WITH_HELMET, 5.9ms\n",
            "video 1/1 (114/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (115/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (116/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 MORE_THAN_TWO_PERSONS, 5.5ms\n",
            "video 1/1 (117/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 MORE_THAN_TWO_PERSONS, 8.9ms\n",
            "video 1/1 (118/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (119/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (120/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 MORE_THAN_TWO_PERSONS, 5.9ms\n",
            "video 1/1 (121/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (122/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 MORE_THAN_TWO_PERSONS, 6.2ms\n",
            "video 1/1 (123/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (124/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (125/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (126/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (127/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 8.0ms\n",
            "video 1/1 (128/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.5ms\n",
            "video 1/1 (129/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (130/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (131/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (132/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (133/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (134/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (135/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (136/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (137/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (138/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (139/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (140/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (141/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.7ms\n",
            "video 1/1 (142/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (143/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 8.9ms\n",
            "video 1/1 (144/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.5ms\n",
            "video 1/1 (145/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (146/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (147/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (148/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (149/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 8.0ms\n",
            "video 1/1 (150/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 10.5ms\n",
            "video 1/1 (151/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 12.8ms\n",
            "video 1/1 (152/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (153/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (154/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.1ms\n",
            "video 1/1 (155/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (156/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (157/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (158/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (159/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.4ms\n",
            "video 1/1 (160/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 8.7ms\n",
            "video 1/1 (161/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (162/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (163/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.9ms\n",
            "video 1/1 (164/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (165/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 8.6ms\n",
            "video 1/1 (166/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 1 WITH_HELMET, 6.4ms\n",
            "video 1/1 (167/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.5ms\n",
            "video 1/1 (168/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (169/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (170/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.2ms\n",
            "video 1/1 (171/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (172/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (173/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.7ms\n",
            "video 1/1 (174/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.7ms\n",
            "video 1/1 (175/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (176/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.0ms\n",
            "video 1/1 (177/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.8ms\n",
            "video 1/1 (178/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 8.5ms\n",
            "video 1/1 (179/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.2ms\n",
            "video 1/1 (180/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (181/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.3ms\n",
            "video 1/1 (182/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (183/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.7ms\n",
            "video 1/1 (184/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.1ms\n",
            "video 1/1 (185/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 6.8ms\n",
            "video 1/1 (186/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 7.2ms\n",
            "video 1/1 (187/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (188/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.8ms\n",
            "video 1/1 (189/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "video 1/1 (190/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.7ms\n",
            "video 1/1 (191/191) /content/drive/.shortcut-targets-by-id/1v9skCOTcYVv8fE9sk_aIVAfzYR24zyB5/DL Project/traffic_compliance_system/processed_video.mp4: 384x640 (no detections), 5.9ms\n",
            "Speed: 0.4ms pre-process, 6.8ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/traffic_compliance_outputs/filtered_output\u001b[0m\n",
            "65 labels saved to /content/traffic_compliance_outputs/filtered_output/labels\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/DL Project/Scripts/emergency.py\", line 37, in <module>\n",
            "    detect_emergency(video_path, output_path, model_path)\n",
            "  File \"/content/drive/MyDrive/DL Project/Scripts/emergency.py\", line 11, in detect_emergency\n",
            "    yolo_model = YOLO(model_path)\n",
            "                 ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/model.py\", line 53, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 147, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 289, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\", line 1306, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\", line 1211, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\", line 115, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1432, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 763, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/DL Project/Scripts/seatbelt.py\", line 4, in <module>\n",
            "    from ultralytics import YOLO\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/__init__.py\", line 11, in <module>\n",
            "    from ultralytics.models import NAS, RTDETR, SAM, YOLO, YOLOE, FastSAM, YOLOWorld\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/models/__init__.py\", line 3, in <module>\n",
            "    from .fastsam import FastSAM\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/models/fastsam/__init__.py\", line 3, in <module>\n",
            "    from .model import FastSAM\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/models/fastsam/model.py\", line 5, in <module>\n",
            "    from ultralytics.engine.model import Model\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\", line 11, in <module>\n",
            "    from ultralytics.cfg import TASK2DATA, get_cfg, get_save_dir\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 13, in <module>\n",
            "    from ultralytics.utils import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/utils/__init__.py\", line 24, in <module>\n",
            "    import matplotlib.pyplot as plt\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 1573, in <module>\n",
            "    from matplotlib.cm import _colormaps as colormaps  # noqa: E402\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/cm.py\", line 24, in <module>\n",
            "    from matplotlib._cm_listed import cmaps as cmaps_listed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/_cm_listed.py\", line 1800, in <module>\n",
            "    _twilight_shifted_data = (_twilight_data[len(_twilight_data)//2:] +\n",
            "                                             ^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:None;base64,/content/traffic_compliance_outputs/filtered_output/processed_video(after_seatbelt).mp4\" type=\"None\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Traffic Compliance System - Deep Learning Project\n",
        "# This notebook implements a comprehensive traffic compliance detection system capable of:\n",
        "# 1. Detecting standard traffic violations (speeding, lane changes)\n",
        "# 2. Detecting multiple riders on motorcycles (>2 people)\n",
        "# 3. Detecting riders without helmets\n",
        "# 4. License plate recognition\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files, drive\n",
        "import torch\n",
        "from IPython.display import display, HTML, Image\n",
        "import pytesseract\n",
        "from PIL import Image as PILImage\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "from IPython.display import Video\n",
        "\n",
        "# Mount Google Drive for saving results (optional but recommended)\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory\n",
        "PROJECT_DIR = '/content/drive/MyDrive/DL Project/traffic_compliance_system'\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_DIR}/detected_violations\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_DIR}/processed_frames\", exist_ok=True)\n",
        "\n",
        "# 2nd installation code\n",
        "\n",
        "\n",
        "video_path = \"/content/drive/MyDrive/Uploaded videos/traffic3.mp4\"\n",
        "\n",
        "\n",
        "!python \"/content/drive/MyDrive/DL Project/Scripts/main.py\" \"{video_path}\"\n",
        "\n",
        "class_names = ['helmet', 'mobile_usage', 'no_helmet', 'triple_ride']\n",
        "\n",
        "!python /content/yolov5/detect.py --weights \"/content/drive/MyDrive/DL Project/model/best_3rider.pt\" \\\n",
        "                  --source \"/content/drive/MyDrive/DL Project/traffic_compliance_system/processed_video.mp4\" \\\n",
        "                  --conf 0.3 \\\n",
        "                  --save-txt \\\n",
        "                  --save-conf \\\n",
        "                  --project /content/traffic_compliance_outputs \\\n",
        "                  --name filtered_output \\\n",
        "                  --exist-ok\n",
        "\n",
        "!python \"/content/drive/MyDrive/DL Project/Scripts/emergency.py\"\n",
        "\n",
        "!python \"/content/drive/MyDrive/DL Project/Scripts/seatbelt.py\"\n",
        "\n",
        "output_path = \"/content/traffic_compliance_outputs/filtered_output/processed_video(after_seatbelt).mp4\"\n",
        "\n",
        "display(Video(output_path, embed=True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files, drive\n",
        "import torch\n",
        "from IPython.display import display, HTML, Image\n",
        "import pytesseract\n",
        "from PIL import Image as PILImage\n",
        "from ultralytics import YOLO\n",
        "import supervision as sv\n",
        "from IPython.display import Video\n",
        "\n",
        "# Mount Google Drive for saving results (optional but recommended)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory\n",
        "PROJECT_DIR = '/content/drive/MyDrive/DL Project/traffic_compliance_system'\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_DIR}/detected_violations\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJECT_DIR}/processed_frames\", exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnsgZmB63YW-",
        "outputId": "1052ec67-9c71-4f4a-988b-4906611b068a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2kouDLmmhOf",
        "outputId": "684bf80d-3b8b-4d39-fb68-e0462a910386"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.36.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.0 watchdog-6.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.5-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken \"2w89D5gOXVZpohhkerRzIdrvOd7_5BVJUJBSG53pZet6iN5Ni\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PA55I_8yEno",
        "outputId": "8041b050-6bf9-4ce0-a137-e677253cb8d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "authtoken = getpass(\"Paste your ngrok authtoken: \")\n",
        "!ngrok config add-authtoken {authtoken}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "GZDeZ0sryYWS",
        "outputId": "93b9daff-cb3d-4086-eda6-59bd434022fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a1d2fc31284b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgetpass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mauthtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Paste your ngrok authtoken: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ngrok config add-authtoken {authtoken}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from IPython.display import display, Video\n",
        "import base64\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Set page title and layout\n",
        "st.set_page_config(page_title=\"Traffic Compliance Detection System\", layout=\"wide\")\n",
        "\n",
        "# Add header with styling\n",
        "st.title(\"Traffic Compliance Detection System\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "# Create sidebar for control buttons\n",
        "with st.sidebar:\n",
        "    st.header(\"Controls\")\n",
        "    st.markdown(\"Upload a video and use the detect buttons to process it.\")\n",
        "\n",
        "# Create file uploader\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload Video\", type=[\"mp4\", \"avi\", \"mov\"])\n",
        "\n",
        "# Initialize session state variables if they don't exist\n",
        "if \"video_path\" not in st.session_state:\n",
        "    st.session_state.video_path = None\n",
        "if \"output_path\" not in st.session_state:\n",
        "    st.session_state.output_path = None\n",
        "if \"detection_complete\" not in st.session_state:\n",
        "    st.session_state.detection_complete = False\n",
        "\n",
        "# Process uploaded file\n",
        "if uploaded_file is not None:\n",
        "    # Create directory if it doesn't exist\n",
        "    save_dir = \"/content/Uploaded videos\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Save uploaded file to the directory\n",
        "    save_path = os.path.join(save_dir, uploaded_file.name)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "    # Update session state with video path\n",
        "    st.session_state.video_path = save_path\n",
        "    st.sidebar.success(f\"File uploaded successfully: {uploaded_file.name}\")\n",
        "\n",
        "    # Display original video\n",
        "    st.subheader(\"Uploaded Video\")\n",
        "    st.video(uploaded_file)\n",
        "\n",
        "# Create detect buttons\n",
        "col1, col2 = st.sidebar.columns(2)\n",
        "\n",
        "with col1:\n",
        "    detect_button = st.button(\"Detect\", type=\"primary\")\n",
        "\n",
        "with col2:\n",
        "    license_button = st.button(\"License Detection\")\n",
        "\n",
        "# Function to run detection script\n",
        "def run_detection():\n",
        "    video_path = st.session_state.video_path\n",
        "\n",
        "    if video_path:\n",
        "        with st.spinner(\"Running main script...\"):\n",
        "            # Run main.py\n",
        "            subprocess.run(f\"python '/content/drive/MyDrive/DL Project/Scripts/main.py' '{video_path}'\", shell=True)\n",
        "\n",
        "        with st.spinner(\"Running YOLOv5 detection...\"):\n",
        "            # Define class names for detection\n",
        "            class_names = ['helmet', 'mobile_usage', 'no_helmet', 'triple_ride']\n",
        "\n",
        "            # Run YOLOv5 detection\n",
        "            subprocess.run(f\"python /content/yolov5/detect.py --weights '/content/drive/MyDrive/DL Project/model/best_3rider.pt' \"\n",
        "                           f\"--source '/content/drive/MyDrive/DL Project/traffic_compliance_system/processed_video.mp4' \"\n",
        "                           f\"--conf 0.3 --save-txt --save-conf --project /content/traffic_compliance_outputs \"\n",
        "                           f\"--name filtered_output --exist-ok\", shell=True)\n",
        "\n",
        "        with st.spinner(\"Running emergency detection...\"):\n",
        "            # Run emergency.py\n",
        "            subprocess.run(\"python '/content/drive/MyDrive/DL Project/Scripts/emergency.py'\", shell=True)\n",
        "\n",
        "        with st.spinner(\"Running seatbelt detection...\"):\n",
        "            # Run seatbelt.py\n",
        "            subprocess.run(\"python '/content/drive/MyDrive/DL Project/Scripts/seatbelt.py'\", shell=True)\n",
        "\n",
        "        # Update output path\n",
        "        st.session_state.output_path = \"/content/traffic_compliance_outputs/filtered_output/processed_video(after_seatbelt).mp4\"\n",
        "        st.session_state.detection_complete = True\n",
        "\n",
        "        return True\n",
        "    else:\n",
        "        st.error(\"Please upload a video first\")\n",
        "        return False\n",
        "\n",
        "# Handle detect button click\n",
        "if detect_button:\n",
        "    if st.session_state.video_path:\n",
        "        success = run_detection()\n",
        "        if success:\n",
        "            st.success(\"Detection completed successfully!\")\n",
        "    else:\n",
        "        st.error(\"Please upload a video first\")\n",
        "\n",
        "# Handle license detection button click\n",
        "if license_button:\n",
        "    st.info(\"License detection functionality is not implemented yet\")\n",
        "\n",
        "# Display processed video if detection is complete\n",
        "if st.session_state.detection_complete and st.session_state.output_path:\n",
        "    st.subheader(\"Processed Video\")\n",
        "    st.video(st.session_state.output_path)\n",
        "\n",
        "# Add information section\n",
        "with st.expander(\"About\"):\n",
        "    st.markdown(\"\"\"\n",
        "    ## Traffic Compliance Detection System\n",
        "\n",
        "    This application detects several traffic violations:\n",
        "    - Helmet usage violations\n",
        "    - Mobile phone usage while driving\n",
        "    - Triple riding on two-wheelers\n",
        "    - Emergency vehicle detection\n",
        "    - Seatbelt compliance\n",
        "\n",
        "    Upload a video and click 'Detect' to process it.\n",
        "    \"\"\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_CkpwozmhUS",
        "outputId": "9fbe2ce8-9455-4363-ec96-99fe74dc7f1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# license and detect both integrated -\n",
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "\n",
        "st.set_page_config(page_title=\"Traffic Compliance Detection System\", layout=\"wide\")\n",
        "\n",
        "st.title(\"Traffic Compliance Detection System\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"Controls\")\n",
        "    st.markdown(\"Upload a video and use the detect buttons to process it.\")\n",
        "\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload Video\", type=[\"mp4\", \"avi\", \"mov\"])\n",
        "\n",
        "if \"video_path\" not in st.session_state:\n",
        "    st.session_state.video_path = None\n",
        "if \"output_path\" not in st.session_state:\n",
        "    st.session_state.output_path = None\n",
        "if \"detection_complete\" not in st.session_state:\n",
        "    st.session_state.detection_complete = False\n",
        "if \"license_plates\" not in st.session_state:\n",
        "    st.session_state.license_plates = []\n",
        "if \"license_detection_complete\" not in st.session_state:\n",
        "    st.session_state.license_detection_complete = False\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Create directory if it doesn't exist\n",
        "    save_dir = \"/content/drive/MyDrive/Uploaded videos\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Save\n",
        "    save_path = os.path.join(save_dir, uploaded_file.name)\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(uploaded_file.getbuffer())\n",
        "\n",
        "\n",
        "    st.session_state.video_path = save_path\n",
        "    st.sidebar.success(f\"File uploaded successfully: {uploaded_file.name}\")\n",
        "\n",
        "\n",
        "    st.subheader(\"Uploaded Video\")\n",
        "    st.video(uploaded_file)\n",
        "\n",
        "\n",
        "col1, col2 = st.sidebar.columns(2)\n",
        "\n",
        "with col1:\n",
        "    detect_button = st.button(\"Detect\", type=\"primary\")\n",
        "\n",
        "with col2:\n",
        "    license_button = st.button(\"License Detection\", type=\"primary\")\n",
        "\n",
        "def run_detection():\n",
        "    video_path = st.session_state.video_path\n",
        "\n",
        "    if video_path:\n",
        "        with st.spinner(\"Running main script...\"):\n",
        "            # Run main.py\n",
        "            subprocess.run(f\"python '/content/drive/MyDrive/DL Project/Scripts/main.py' '{video_path}'\", shell=True)\n",
        "\n",
        "        with st.spinner(\"Running YOLOv5 detection...\"):\n",
        "\n",
        "            class_names = ['helmet', 'mobile_usage', 'no_helmet', 'triple_ride']\n",
        "\n",
        "\n",
        "            subprocess.run(f\"python /content/yolov5/detect.py --weights '/content/drive/MyDrive/DL Project/model/best_3rider.pt' \"\n",
        "                           f\"--source '/content/drive/MyDrive/DL Project/traffic_compliance_system/processed_video.mp4' \"\n",
        "                           f\"--conf 0.3 --save-txt --save-conf --project /content/traffic_compliance_outputs \"\n",
        "                           f\"--name filtered_output --exist-ok\", shell=True)\n",
        "\n",
        "        with st.spinner(\"Running emergency detection...\"):\n",
        "            # Runing emergency.py\n",
        "            subprocess.run(\"python '/content/drive/MyDrive/DL Project/Scripts/emergency.py'\", shell=True)\n",
        "\n",
        "        with st.spinner(\"Running seatbelt detection...\"):\n",
        "            # Runing seatbelt.py\n",
        "            subprocess.run(\"python '/content/drive/MyDrive/DL Project/Scripts/seatbelt.py'\", shell=True)\n",
        "\n",
        "\n",
        "        st.session_state.output_path = \"/content/traffic_compliance_outputs/filtered_output/processed_video(after_seatbelt).mp4\"\n",
        "        st.session_state.detection_complete = True\n",
        "\n",
        "        return True\n",
        "    else:\n",
        "        st.error(\"Please upload a video first\")\n",
        "        return False\n",
        "\n",
        "def run_license_detection():\n",
        "    video_path = st.session_state.video_path\n",
        "\n",
        "    if video_path:\n",
        "        with st.spinner(\"Running license plate detection...\"):\n",
        "            subprocess.run(f\"python '/content/drive/MyDrive/License-Plate-Extraction/main.py' '{video_path}'\", shell=True)\n",
        "\n",
        "\n",
        "            json_path = \"/content/drive/MyDrive/License-Plate-Extraction/json/LicensePlateData.json\"\n",
        "\n",
        "            try:\n",
        "                with open(json_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                unique_license_plates = set()\n",
        "\n",
        "                if data:\n",
        "                    for entry in data:\n",
        "                        plates = entry.get(\"License Plate\", [])\n",
        "                        for plate in plates:\n",
        "                            if len(plate) == 10 :\n",
        "                                unique_license_plates.add(plate)\n",
        "\n",
        "                    st.session_state.license_plates = list(unique_license_plates)\n",
        "                    st.session_state.license_detection_complete = True\n",
        "                    return True\n",
        "                else:\n",
        "                    st.error(\"No entries found in the JSON file.\")\n",
        "                    return False\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error processing license plate data: {str(e)}\")\n",
        "                return False\n",
        "    else:\n",
        "        st.error(\"Please upload a video first\")\n",
        "        return False\n",
        "\n",
        "if detect_button:\n",
        "    if st.session_state.video_path:\n",
        "        success = run_detection()\n",
        "        if success:\n",
        "            st.success(\"Detection completed successfully!\")\n",
        "    else:\n",
        "        st.error(\"Please upload a video first\")\n",
        "\n",
        "if license_button:\n",
        "    if st.session_state.video_path:\n",
        "        success = run_license_detection()\n",
        "        if success:\n",
        "            st.success(\"License plate detection completed successfully!\")\n",
        "    else:\n",
        "        st.error(\"Please upload a video first\")\n",
        "\n",
        "if st.session_state.detection_complete and st.session_state.output_path:\n",
        "    st.subheader(\"Processed Video\")\n",
        "    st.video(st.session_state.output_path)\n",
        "\n",
        "if st.session_state.license_detection_complete and st.session_state.license_plates:\n",
        "    st.subheader(\"Detected License Plates\")\n",
        "\n",
        "    license_container = st.container()\n",
        "    with license_container:\n",
        "        st.markdown(\" License Plates \")\n",
        "\n",
        "        for plate in st.session_state.license_plates:\n",
        "            st.markdown(f\"\"\"\n",
        "            <div style=\"\n",
        "                background-color: #ffffff;\n",
        "                color: #000000;\n",
        "                padding: 10px;\n",
        "                border-radius: 5px;\n",
        "                margin-bottom: 10px;\n",
        "                font-size: 18px;\n",
        "                font-family: monospace;\n",
        "                border-left: 4px solid #4CAF50;\n",
        "            \">\n",
        "                {plate}\n",
        "            </div>\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    if st.session_state.license_plates:\n",
        "        import pandas as pd\n",
        "        import io\n",
        "\n",
        "        df = pd.DataFrame(st.session_state.license_plates, columns=[\"License Plate\"])\n",
        "        csv = df.to_csv(index=False).encode('utf-8')\n",
        "\n",
        "        st.download_button(\n",
        "            label=\"Download License Plates as CSV\",\n",
        "            data=csv,\n",
        "            file_name=\"detected_license_plates.csv\",\n",
        "            mime=\"text/csv\",\n",
        "        )\n",
        "\n",
        "# Add information section\n",
        "with st.expander(\"About\"):\n",
        "    st.markdown(\"\"\"\n",
        "    ## Traffic Compliance Detection System\n",
        "\n",
        "    This application detects several traffic violations:\n",
        "    - Helmet usage violations\n",
        "    - Mobile phone usage while driving\n",
        "    - Triple riding on two-wheelers\n",
        "    - Emergency vehicle detection\n",
        "    - Seatbelt compliance\n",
        "    - License plate detection\n",
        "\n",
        "    Upload a video and click 'Detect' to process it for violations or 'License Detection' to identify license plates.\n",
        "    \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D9hJaDHJsyG",
        "outputId": "092cadd9-765e-4462-b244-65aef7ed32fd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    # Start streamlit in a thread\n",
        "    def start_streamlit():\n",
        "        !streamlit run app.py --server.port 8501\n",
        "\n",
        "    thread = threading.Thread(target=start_streamlit)\n",
        "    thread.start()\n",
        "\n",
        "    # Wait a few seconds for Streamlit to spin up\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Establish a public URL\n",
        "    public_url = ngrok.connect(8501, \"http\")\n",
        "    print(f\"Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "id": "WDgvH-zBnTKT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_streamlit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZA1mrSl0_UV",
        "outputId": "4d66a2ce-2939-4698-f52d-3b95680f4005"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2025-04-30 21:55:23.483 Port 8501 is already in use\n",
            "Streamlit app is live at: NgrokTunnel: \"https://c7b8-34-125-195-171.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill all tunnels\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "VxUuQ7vSVl3s"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}